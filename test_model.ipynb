{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=False)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights, mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
    "\n",
    "weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "model = resnet50(weights=weights).to(device)\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2048, 512, bias=False),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.Dropout(p=0.5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, 7),\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(\"model_states/epoch3.pt\"))\n",
    "#model.fc.load_state_dict(torch.load(\"layers.pt\"))\n",
    "\n",
    "# weights = MobileNet_V3_Large_Weights.IMAGENET1K_V2\n",
    "# model = mobilenet_v3_large(weights=weights).to(device)\n",
    "# model.classifier = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(960, 960, bias=False),\n",
    "#     torch.nn.BatchNorm1d(960),\n",
    "#     torch.nn.Dropout(p=0.2),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(960, 960, bias=False),\n",
    "#     torch.nn.BatchNorm1d(960),\n",
    "#     torch.nn.Dropout(p=0.2),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(960, 7),\n",
    "# ).to(device)\n",
    "# model.load_state_dict(torch.load(\"mobile_states/epoch20.pt\"))\n",
    "#model.classifier.load_state_dict(torch.load(\"layers.pt\"))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "class CountingDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        with open(annotations_file) as f:\n",
    "            self.labels_dict = json.load(f)\n",
    "        self.img_dir = img_dir\n",
    "        self.images_list = [x for x in os.listdir(img_dir) if \"testset3\" in x]\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images_list[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = read_image(img_path) / 255.0\n",
    "\n",
    "        label = int(self.labels_dict[img_name])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "annotations_file = \"../Apple/test_data/counting/ground_truth.json\"\n",
    "img_dir = \"../Apple/test_data/counting/images/\"\n",
    "transform = T.Compose([\n",
    "    T.Resize((224,224), antialias=True),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "test_dataset = CountingDataset(annotations_file, img_dir, transform=transform)\n",
    "\n",
    "batch_size = 128\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "truths = []\n",
    "preds = []\n",
    "\n",
    "confusion_matrix = np.zeros((7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for test_images, test_labels in (test_dataloader):\n",
    "        pred = model(test_images.to(device)).argmax(dim=1).cpu()\n",
    "        truths += test_labels.tolist()\n",
    "        preds += pred.tolist()\n",
    "\n",
    "        for label,p in zip(test_labels.tolist(), pred.tolist()):\n",
    "            confusion_matrix[label, p] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in confusion_matrix:\n",
    "    s = np.sum(row)\n",
    "    if s == 0:\n",
    "        continue\n",
    "    row /= np.sum(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x284183c8f10>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAScAAAD8CAYAAAA11GIZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAATUUlEQVR4nO3dfbBdVX3G8e+TSwRFhNGgYJJKZhqdprQF5k4sg4MoKgGd0Jk6HeJgq8M0fxQcrLYOth1Q+pc6tbZTSpsCioqmGqWTsdH4BqV2hCa8FEkCNqbU3AgTeVEBgST3Pv3j7EuP15t79iVnn7PO3c9nZg9n77POWuvq8GO97bVkm4iI0iwadgUiImaT4BQRRUpwiogiJThFRJESnCKiSAlOEVGkBKeIOGKSbpC0X9J9h/lekv5W0m5J90o6o1eeCU4R0Q+fAtbM8f35wMrqWg9c2yvDBKeIOGK2bwMemyPJhcCn3XE7cIKkk+fK86h+VnDa8S8d80lLFzeRdU8P//cJQykXwM8eGFrZ0S7P8BQH/KyOJI/z3nCsH31sslbaO+99dgfwTNejDbY3zKO4pcDervuJ6tlDh/tBI8HppKWLuXbzq5rIuqePvXntUMoFOLTnwaGVHe1yh791xHk88tgkd2xdVivt4pN/8Izt8SMudB4aCU4RMQrMpKcGVdg+YHnX/bLq2WFlzCmipQxM4VpXH2wGfr+atftt4Ke2D9ulg7ScIlptiv60nCR9HjgHWCJpArgKWAxg+x+ALcAFwG7g58C7e+WZ4BTRUsYc7FO3zva6Ht8buHQ+eSY4RbSUgcn+dNkakeAU0WJ9Gk9qRIJTREsZmCx4J9wEp4gWG9hCguchwSmipYwz5hQR5bHhYLmxKcEpor3EJEf0el6jaq0Ql7RG0gPVXixXNF2piGiegSnXu4ahZ8tJ0hhwDfBmOm8Sb5O02fbOpisXEc0a9ZbTamC37T22DwAb6ezNEhEjrLMIU7WuYagz5jTbPiyvnZlI0no6O9zx8ldmKCuidAYOutx3//tWM9sbbI/bHj/hpWP9yjYiGmLEJItqXcNQp4kz731YImI0TLncMac6wWkbsFLSCjpB6SLgHY3WKiIaNz3mVKqewcn2IUmXAVuBMeAG2zsar1lENExMFjzmVGvk2vYWOptFRcQC0dkJc8SDU0QsPLY44HInrxKcIlpsapTHnCJiYeoMiKdbFxHFWQAD4hGx8GRAPCKKNTniizAjYgEy4qDLDQHl1iwiGpUB8YgoklH7unUP7zqOj46/vomse/rQXV8cSrkAV/36cP5mgKmnnx5a2UBnQ+oYORkQj4ji2GQpQUSUpzMgntdXIqJAGRCPiOIYjfxmcxGxQKXlFBHF6Zxbl+AUEcUp+8TfBKeIluocDZXZuogojK2iu3Xl1iwiGjfpRbWuXiStkfSApN2Srpjl+1+RdIukuyXdK+mCXnkmOEW0VGc/J9W65iJpDLgGOB9YBayTtGpGsr8AvmD7dDrHy/19r/qlWxfRWn3bCXM1sNv2HgBJG4ELgZ1daQy8pPp8PPCjXpn2rJmkGyTtl3TfvKscEcXqLCVQrQtYIml717W+K6ulwN6u+4nqWbcPARdLmqBzzNx7etWvTsvpU8DfAZ+ukTYiRsQ83617xPb4ERS3DviU7b+SdCbwGUmn2p463A/qnPh7m6RTjqBSEVGoPm2Zsg9Y3nW/rHrW7RJgDYDt70o6BlgC7D9cpn0bEJe0frrJd8DP9CvbiGhIZ8sU1bp62AaslLRC0gvoDHhvnpHmh8C5AJJ+DTgG+PFcmfZtQNz2BmADwPFHnZidxyJGQD9e/LV9SNJlwFZgDLjB9g5JVwPbbW8G3g/8k6Q/pjPc9S577h0KM1sX0VKdXQn603myvYXOQHf3syu7Pu8EzppPnglOES3VeX2l3KWOdZYSfB74LvAaSROSLmm+WhHRvE7Lqc41DHVm69YNoiIRMXi9Vn8PU7p1ES01PVtXqgSniBYreVeCBKeIlsoe4hFRJAOH0nKKiBKlWxcR5XG6dRFRoOnN5kqV4BTRYmk5RURxpjebK1UzwWlqCj/9dCNZ9/KhM94ylHIBPrzj60Mr+8qVZw6tbAAfOjTU8mP+jDg0lQHxiChQxpwiojxuY7cuIorXzjGniBgJCU4RURwjJjMgHhElyoB4RBTHGRCPiFI5wSkiypMXfyOiUGk5RURxbJicSnCKiAKVPFtX59y65ZJukbRT0g5Jlw+iYhHRLNPp1tW5hqFOy+kQ8H7bd0k6DrhT0jeq44UjYmSN+IC47YeAh6rPT0jaBSwFEpwiRpw97Boc3rzGnCSdApwO3DHLd+uB9QDH6Nh+1C0iGrYgZuskvRj4EvBe2z+b+b3tDcAGgOMXvazgeBwRMD1bN+Lv1klaTCcw3WT7y81WKSIGZaS7dZIEXA/ssv3x5qsUEYNScreuTpvuLOCdwBsl3VNdFzRcr4homKm3jKDYpQS2vwMFr9SKiOet4F5drZZTRCxEBk+p1tWLpDWSHpC0W9IVh0nze12LuT/XK8+8vhLRYv3oskkaA64B3gxMANskbe5eqC1pJfBB4Czbj0t6ea9803KKaDG73tXDamC37T22DwAbgQtnpPlD4Brbj3fK9f5emSY4RbTUPN+tWyJpe9e1viurpcDervuJ6lm3VwOvlvQfkm6XtKZX/dKti2grA/W7dY/YHj+C0o4CVgLnAMuA2yT9hu2fHO4HaTlFtFifunX7gOVd98uqZ90mgM22D9r+H+D7dILVYSU4RbRWvZm6GrN124CVklZIegFwEbB5Rpp/odNqQtISOt28PXNlmuAU0Wauec2VhX0IuAzYCuwCvmB7h6SrJa2tkm0FHpW0E7gF+FPbj86Vb8acItrK/Xt9xfYWYMuMZ1d2fTbwvuqqpZHgZJupZ55pIuueFo2NDaVcgA9c+kdDK/ukf/vB0MoGePysx4ZafjxPBS8RT8spotXKfTMtwSmizaaGXYHDS3CKaKv5rXMauASniBYb6c3mImIBS3CKiCKlWxcRJVJaThFRHAtqbCQ3LAlOEW2WllNEFCnBKSKKlOAUEcUZ9UWYko4BbgOOrtJvsn1V0xWLiOaN+mzds8AbbT9ZHUv+HUlftX17w3WLiKaNcnCq9mF5srpdXF0F/0kRUVfJLadaO2FKGpN0D7Af+IbtO2ZJs376ZIaDPNvnakZEI6x61xDUCk62J22fRmfj8tWSTp0lzQbb47bHF3N0n6sZEX1Xd4veIbWu5rWHeHWMyy1AzzOnImIEjHJwknSipBOqzy+kc+Tw/Q3XKyIGQFP1rmGoM1t3MnBjdR76IjonK3yl2WpFxEAUPCBeZ7buXuD0AdQlIgZILnu2LivEI9pslFeIR8QClpZTRJQo3bqIKI+HNxNXR4JTRJul5RQRRUpwiogSlTzmNK/XVyIiBiUtp4g2K7jllOAU0VaZrRusqaeeGlrZR2/ZNrSyN153z9DKBjiP04ZafjxPaTlFRGlE2QPiCU4RbVZwcMpsXURb+f93Juh19SJpjaQHJO2WdMUc6X5XkiWN98ozwSmizaZqXnOo9nq7BjgfWAWsk7RqlnTHAZcDv3QGwWwSnCJarE8tp9XAbtt7bB8ANgIXzpLuL4GPAM/UqVuCU0Sb1d9DfMn06UrVtb4rl6XA3q77ierZcySdASy3/a91q5YB8Yi2mt/hBY/Y7jlONBtJi4CPA++az+8SnCJarE9LCfYBy7vul1XPph0HnArcKgngJGCzpLW2tx8u0wSniDbrT3DaBqyUtIJOULoIeMdzRdg/BZZM30u6FfiTuQITZMwpotX6cTSU7UPAZcBWYBedE5p2SLpa0trnW7e0nCLaqo8HZtreAmyZ8ezKw6Q9p06etVtOksYk3S0pZ9ZFLACaxzUM8+nWXU6nyRYRC8UoH0cOIGkZ8FbgumarExGD1K/XV5pQt+X0CeADzLGQXdL66QVaB3m2H3WLiKaNcstJ0tuA/bbvnCud7Q22x22PL+bovlUwIhri/szWNaXObN1ZwFpJFwDHAC+R9FnbFzdbtYho3ChvmWL7g7aX2T6FzuKqbycwRSwMJY85ZZ1TRJsV3HKaV3CyfStwayM1iYiByza9EVEe03MjuWFKcIpoqRxwEBHlSnCKiBLJ5UanBKeIthri6u86EpwiWixjThFRpGG9mlJHglNEm6XlFBHFGeKrKXUkOEW0WYJTNO28V5421PK3/uieoZU97L99VGURZkQUS1PlRqcEp4i2yjqniChVlhJERJnScoqIEmVAPCLKYyAv/kZEiTLmFBHFyTqniCiTnW5dRJQpLaeIKNOoBydJDwJPAJPAIdvjTVYqIgZjobSc3mD7kcZqEhGDZWCy3OiUbl1Ei5XcclpUM52Br0u6U9L62RJIWi9pu6TtB3m2fzWMiOZMz9j1unqQtEbSA5J2S7pilu/fJ2mnpHslfUvSq3rlWTc4vc72GcD5wKWSzv7lv9EbbI/bHl/M0TWzjYhhkutdc+YhjQHX0IkPq4B1klbNSHY3MG77N4FNwEd71a1WcLK9r/rnfuBmYHWd30VEwTyPa26rgd2299g+AGwELvyFouxbbP+8ur0dWNYr057BSdKxko6b/gy8BbivZ3UjomgCNOlaF7BketimurqHd5YCe7vuJ6pnh3MJ8NVe9aszIP4K4GZJ0+k/Z/trNX4XEYWbx4m/j/RjCZGki4Fx4PW90vYMTrb3AL91pJWKiML0byfMfcDyrvtl1bNfIOlNwJ8Dr7fdc9as7oB4RCw4NWfqereutgErJa2Q9ALgImBzdwJJpwP/CKytxq57yjqniBbrxzon24ckXQZsBcaAG2zvkHQ1sN32ZuBjwIuBL1ZDRD+0vXaufBOcItqsT7sS2N4CbJnx7Mquz2+ab54JThFtZaZn4oqU4BTRZuXGpgSniDabx1KCgUtwimizBKeIKI6BHHAQEaURTrcuIgo1VW7TKcEp+uK8V5427CrEfKVbFxGlSrcuIsqU4BQR5cmhmhFRopy+EhGlyphTRJQpwSkiimNgKsEpIoqTAfGIKFWCU0QUx8BkuUvEE5wiWsvgcoNTrdNXJJ0gaZOk+yXtknRm0xWLiAHoz+krjajbcvob4Gu2314d/fKiBusUEYMw6rN1ko4HzgbeBVCdhX6g2WpFxEAUPCBep1u3Avgx8ElJd0u6TtKxMxNJWj99jvpBeh7mGRElKLhbVyc4HQWcAVxr+3TgKeCKmYlsb7A9bnt8MUf3uZoR0Xc2TE7Wu4agTnCaACZs31Hdb6ITrCJi1I1yy8n2w8BeSa+pHp0L7Gy0VhExGAUHp7qzde8Bbqpm6vYA726uShExGB7t2ToA2/cA481WJSIGyuCCF2FmhXhEm+X1lYgojp2joSKiUAUvwkxwimgxp+UUEeXJZnMRUaJRf/E3IhYmAx7Sqyl11NrPKSIWIFebzdW5epC0RtIDknZL+qV3byUdLemfq+/vkHRKrzwTnCJazFOudc1F0hhwDXA+sApYJ2nVjGSXAI/b/lXgr4GP9KpbglNEm/Wn5bQa2G17T7Xf20bgwhlpLgRurD5vAs6VpLkybWTM6Qkef+Sb3vS/z/PnS4BH+lmflJ2yF2DZrzrSCjzB41u/6U1LaiY/RtL2rvsNtjdUn5cCe7u+mwBeO+P3z6WxfUjST4GXMcf/Bo0EJ9snPt/fStpueyjv8aXslN2GsqfZXjPM8ntJty4ijtQ+YHnX/bLq2axpJB0FHA88OlemCU4RcaS2ASslrai2VboI2DwjzWbgD6rPbwe+bc+9ArTEdU4beidJ2Sk7ZZeiGkO6DNgKjAE32N4h6Wpgu+3NwPXAZyTtBh6jE8DmpB7BKyJiKNKti4giJThFRJGKCk69lsA3WO4NkvZLum9QZXaVvVzSLZJ2Stoh6fIBln2MpP+U9F9V2R8eVNlddRirzkP8yoDLfVDS9yTdM2P9ziDKPkHSJkn3S9ol6cxBlj8qihlzqpbAfx94M51FXNuAdbYbP+lF0tnAk8CnbZ/adHkzyj4ZONn2XZKOA+4EfmdAf7eAY20/KWkx8B3gctu3N112Vx3eR2d/+pfYftsAy30QGLc98EWYkm4E/t32ddXs1ots/2TQ9ShdSS2nOkvgG2H7NjozCANn+yHbd1WfnwB20VlNO4iybfvJ6nZxdQ3sv1aSlgFvBa4bVJnDJul44Gw6s1fYPpDANLuSgtNsS+AH8i9pKao3tU8H7uiRtJ9ljkm6B9gPfKPr8NRB+ATwAWAY2zEa+LqkOyWtH2C5K4AfA5+surPXSTp2gOWPjJKCU6tJejHwJeC9tn82qHJtT9o+jc6q3tWSBtKtlfQ2YL/tOwdR3ixeZ/sMOm/SX1p17QfhKDonZl9r+3TgKWBg46ujpKTgVGcJ/IJUjfd8CbjJ9peHUYeqa3ELMKj3rc4C1lZjPxuBN0r67IDKxva+6p/7gZvpDCsMwgQw0dVC3UQnWMUMJQWnOkvgF5xqUPp6YJftjw+47BMlnVB9fiGdyYj7B1G27Q/aXmb7FDr/X3/b9sWDKFvSsdXkA1WX6i3AQGZqbT8M7JX0murRuUDjkx+jqJjXVw63BH4QZUv6PHAOsETSBHCV7esHUTadFsQ7ge9VYz8Af2Z7ywDKPhm4sZopXQR8wfZAp/SH5BXAzdV2QkcBn7P9tQGW/x7gpuo/wnuAdw+w7JFRzFKCiIhuJXXrIiKek+AUEUVKcIqIIiU4RUSREpwiokgJThFRpASniCjS/wHGxuhWhsSmLgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(confusion_matrix)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_truths = np.array(truths)\n",
    "arr_preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10714285714285714"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(arr_truths-arr_preds) / len(truths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
